{
  "id": "91f6bbe2-ed41-4fd6-bac7-71d5b5864ecb",
  "revision": 0,
  "last_node_id": 101,
  "last_link_id": 187,
  "nodes": [
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        -250,
        330
      ],
      "size": [
        330,
        60
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76,
            161,
            162,
            168
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "models": [
          {
            "name": "qwen_image_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors",
            "directory": "vae"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "qwen_image_vae.safetensors"
      ]
    },
    {
      "id": 77,
      "type": "TextEncodeQwenImageEdit",
      "pos": [
        140,
        400
      ],
      "size": [
        360,
        150
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 132
        },
        {
          "name": "vae",
          "shape": 7,
          "type": "VAE",
          "link": 161
        },
        {
          "name": "image",
          "shape": 7,
          "type": "IMAGE",
          "link": 180
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            163
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "TextEncodeQwenImageEdit",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "prompt": true
          }
        }
      },
      "widgets_values": [
        ""
      ],
      "color": "#223",
      "bgcolor": "#335"
    },
    {
      "id": 75,
      "type": "CFGNorm",
      "pos": [
        550,
        130
      ],
      "size": [
        290,
        60
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 141
        }
      ],
      "outputs": [
        {
          "name": "patched_model",
          "type": "MODEL",
          "links": [
            186
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CFGNorm",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "strength": true
          }
        }
      },
      "widgets_values": [
        1
      ]
    },
    {
      "id": 66,
      "type": "ModelSamplingAuraFlow",
      "pos": [
        550,
        20
      ],
      "size": [
        290,
        60
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 185
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            141
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingAuraFlow",
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        3
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        890,
        20
      ],
      "size": [
        210,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 128
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode",
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        -250,
        170
      ],
      "size": [
        330,
        110
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            131,
            132
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPLoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "models": [
          {
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "directory": "text_encoders"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "qwen_2.5_vl_7b_fp8_scaled.safetensors",
        "qwen_image",
        "default"
      ]
    },
    {
      "id": 88,
      "type": "VAEEncode",
      "pos": [
        370,
        630
      ],
      "size": [
        140,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 178
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 168
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            170
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEEncode",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {}
        }
      },
      "widgets_values": []
    },
    {
      "id": 97,
      "type": "MarkdownNote",
      "pos": [
        550,
        780
      ],
      "size": [
        300,
        190
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "KSampler settings",
      "properties": {},
      "widgets_values": [
        "You can test and find the best setting by yourself. The following table is for reference.\n\n| Model            | Steps | CFG |\n|---------------------|---------------|---------------|\n| Offical             | 50               | 4.0               \n| fp8_e4m3fn             | 20                | 2.5               |\n| fp8_e4m3fn + 4steps LoRA    | 4               | 1.0               |\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 96,
      "type": "MarkdownNote",
      "pos": [
        -210,
        1020
      ],
      "size": [
        280,
        88
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "This node is to avoid poor output results caused by excessively large input image sizes."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 60,
      "type": "SaveImage",
      "pos": [
        890,
        240
      ],
      "size": [
        580,
        650
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 110
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveImage",
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 93,
      "type": "ImageScaleToTotalPixels",
      "pos": [
        -210,
        890
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 177
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            178,
            179,
            180
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ImageScaleToTotalPixels",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "upscale_method": true,
            "megapixels": true
          }
        }
      },
      "widgets_values": [
        "lanczos",
        1
      ]
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        550,
        240
      ],
      "size": [
        300,
        474
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 186
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 164
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 163
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 170
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            128
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler",
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        693325272062431,
        "randomize",
        4,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 101,
      "type": "UnetLoaderGGUF",
      "pos": [
        -205.5718994140625,
        -126.68549346923828
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            187
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UnetLoaderGGUF"
      },
      "widgets_values": [
        "Qwen_Image_Edit-Q3_K_S.gguf"
      ]
    },
    {
      "id": 89,
      "type": "LoraLoaderModelOnly",
      "pos": [
        131.16294860839844,
        -106.91941833496094
      ],
      "size": [
        270,
        82
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 187
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            185
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "models": [
          {
            "name": "Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "url": "https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors",
            "directory": "loras"
          }
        ],
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "lora_name": true,
            "strength_model": true
          }
        }
      },
      "widgets_values": [
        "Qwen-Image-Lightning-4steps-V1.0.safetensors",
        1
      ]
    },
    {
      "id": 78,
      "type": "LoadImage",
      "pos": [
        -220,
        500
      ],
      "size": [
        274.080078125,
        314.0000305175781
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            177
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "image": true,
            "upload": true
          }
        }
      },
      "widgets_values": [
        "fennec_girl_flowers.png",
        "image"
      ]
    },
    {
      "id": 76,
      "type": "TextEncodeQwenImageEdit",
      "pos": [
        140,
        200
      ],
      "size": [
        360,
        150
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 131
        },
        {
          "name": "vae",
          "shape": 7,
          "type": "VAE",
          "link": 162
        },
        {
          "name": "image",
          "shape": 7,
          "type": "IMAGE",
          "link": 179
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            164
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "TextEncodeQwenImageEdit",
        "cnr_id": "comfy-core",
        "ver": "0.3.50",
        "enableTabs": false,
        "tabWidth": 65,
        "tabXOffset": 10,
        "hasSecondTab": false,
        "secondTabText": "Send Back",
        "secondTabOffset": 80,
        "secondTabWidth": 65,
        "ue_properties": {
          "widget_ue_connectable": {
            "prompt": true
          }
        }
      },
      "widgets_values": [
        "the women hold a sign saying \"Tech Practice\""
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 99,
      "type": "MarkdownNote",
      "pos": [
        -830,
        -10
      ],
      "size": [
        540,
        550
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "[Tutorial](https://youtu.be/Xg0W9N5res4)\n\n\n## Model links\n\nYou can find all the models on [Comfy-Org/Qwen-Image_ComfyUI](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/tree/main) and  [Comfy-Org/Qwen-Image-Edit_ComfyUI](https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI) \n\n**Diffusion model**\n\n- Use these to save RAM/VRAM \n [Quantitized model download](https://huggingface.co/QuantStack/Qwen-Image-Edit-GGUF/tree/main)\n\n\n\n- [qwen_image_edit_fp8_e4m3fn.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_edit_fp8_e4m3fn.safetensors)\n\n**LoRA**\n\n- [Qwen-Image-Lightning-4steps-V1.0.safetensors](https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors)\n\n**Text encoder**\n\n- [qwen_2.5_vl_7b_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors)\n\n**VAE**\n\n- [qwen_image_vae.safetensors](https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors)\n\nModel Storage Location\n\n```\nðŸ“‚ ComfyUI/\nâ”œâ”€â”€ ðŸ“‚ models/\nâ”‚   â”œâ”€â”€ ðŸ“‚ diffusion_models/\nâ”‚   â”‚   â””â”€â”€ qwen_image_edit_fp8_e4m3fn.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ loras/\nâ”‚   â”‚   â””â”€â”€ Qwen-Image-Lightning-4steps-V1.0.safetensors\nâ”‚   â”œâ”€â”€ ðŸ“‚ vae/\nâ”‚   â”‚   â””â”€â”€ qwen_image_vae.safetensors\nâ”‚   â””â”€â”€ ðŸ“‚ text_encoders/\nâ”‚       â””â”€â”€ qwen_2.5_vl_7b_fp8_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      110,
      8,
      0,
      60,
      0,
      "IMAGE"
    ],
    [
      128,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      131,
      38,
      0,
      76,
      0,
      "CLIP"
    ],
    [
      132,
      38,
      0,
      77,
      0,
      "CLIP"
    ],
    [
      141,
      66,
      0,
      75,
      0,
      "MODEL"
    ],
    [
      161,
      39,
      0,
      77,
      1,
      "VAE"
    ],
    [
      162,
      39,
      0,
      76,
      1,
      "VAE"
    ],
    [
      163,
      77,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      164,
      76,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      168,
      39,
      0,
      88,
      1,
      "VAE"
    ],
    [
      170,
      88,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      177,
      78,
      0,
      93,
      0,
      "IMAGE"
    ],
    [
      178,
      93,
      0,
      88,
      0,
      "IMAGE"
    ],
    [
      179,
      93,
      0,
      76,
      2,
      "IMAGE"
    ],
    [
      180,
      93,
      0,
      77,
      2,
      "IMAGE"
    ],
    [
      185,
      89,
      0,
      66,
      0,
      "MODEL"
    ],
    [
      186,
      75,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      187,
      101,
      0,
      89,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [
        -270,
        -40,
        370,
        450
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 2 - Upload image for editing",
      "bounding": [
        -270,
        430,
        370,
        400
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step 3 - Prompt",
      "bounding": [
        130,
        130,
        380,
        433.6000061035156
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7810180339005898,
      "offset": [
        935.7207705589116,
        100.68070424683067
      ]
    },
    "frontendVersion": "1.25.9",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}
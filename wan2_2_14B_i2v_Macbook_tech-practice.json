{
  "id": "ec7da562-7e21-4dac-a0d2-f4441e1efd3b",
  "revision": 0,
  "last_node_id": 112,
  "last_link_id": 201,
  "nodes": [
    {
      "id": 38,
      "type": "CLIPLoader",
      "pos": [
        70,
        1360
      ],
      "size": [
        346.391845703125,
        106
      ],
      "flags": {},
      "order": 0,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            74,
            75
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPLoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.45",
        "models": [
          {
            "name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "wan",
        "default"
      ]
    },
    {
      "id": 58,
      "type": "KSamplerAdvanced",
      "pos": [
        920,
        1530
      ],
      "size": [
        304.748046875,
        498.6905822753906
      ],
      "flags": {},
      "order": 28,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 148
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 138
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 139
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 113
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            124
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSamplerAdvanced",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "disable",
        0,
        "fixed",
        20,
        3.5,
        "euler",
        "simple",
        10,
        10000,
        "disable"
      ]
    },
    {
      "id": 57,
      "type": "KSamplerAdvanced",
      "pos": [
        920,
        1110
      ],
      "size": [
        304.748046875,
        334
      ],
      "flags": {},
      "order": 26,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 147
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 136
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 137
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 140
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            113
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSamplerAdvanced",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "enable",
        414601915229497,
        "randomize",
        20,
        3.5,
        "euler",
        "simple",
        0,
        10,
        "enable"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        450,
        1580
      ],
      "size": [
        425.27801513671875,
        180.6060791015625
      ],
      "flags": {},
      "order": 15,
      "mode": 4,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 75
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            135
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 39,
      "type": "VAELoader",
      "pos": [
        70,
        1520
      ],
      "size": [
        344.731689453125,
        59.98149108886719
      ],
      "flags": {},
      "order": 1,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            76,
            141
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.45",
        "models": [
          {
            "name": "wan_2.1_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "wan_2.1_vae.safetensors"
      ]
    },
    {
      "id": 54,
      "type": "ModelSamplingSD3",
      "pos": [
        670,
        1100
      ],
      "size": [
        210,
        60
      ],
      "flags": {},
      "order": 16,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 110
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            147
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingSD3",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        8.000000000000002
      ]
    },
    {
      "id": 55,
      "type": "ModelSamplingSD3",
      "pos": [
        670,
        1230
      ],
      "size": [
        210,
        58
      ],
      "flags": {},
      "order": 17,
      "mode": 4,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 112
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            148
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingSD3",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        8
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        450,
        1380
      ],
      "size": [
        422.84503173828125,
        164.31304931640625
      ],
      "flags": {},
      "order": 14,
      "mode": 4,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 74
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            134
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 37,
      "type": "UNETLoader",
      "pos": [
        70,
        1100
      ],
      "size": [
        346.7470703125,
        82
      ],
      "flags": {},
      "order": 2,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            110
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UNETLoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.45",
        "models": [
          {
            "name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": [
        "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
        "default"
      ]
    },
    {
      "id": 56,
      "type": "UNETLoader",
      "pos": [
        70,
        1230
      ],
      "size": [
        346.7470703125,
        82
      ],
      "flags": {},
      "order": 3,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            112
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UNETLoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.45",
        "models": [
          {
            "name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
            "directory": "diffusion_models"
          }
        ]
      },
      "widgets_values": [
        "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
        "default"
      ]
    },
    {
      "id": 63,
      "type": "WanImageToVideo",
      "pos": [
        480,
        1860
      ],
      "size": [
        342.5999755859375,
        210
      ],
      "flags": {},
      "order": 22,
      "mode": 4,
      "inputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 134
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 135
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 141
        },
        {
          "name": "clip_vision_output",
          "shape": 7,
          "type": "CLIP_VISION_OUTPUT",
          "link": null
        },
        {
          "name": "start_image",
          "shape": 7,
          "type": "IMAGE",
          "link": 133
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            136,
            138
          ]
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "slot_index": 1,
          "links": [
            137,
            139
          ]
        },
        {
          "name": "latent",
          "type": "LATENT",
          "slot_index": 2,
          "links": [
            140
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "WanImageToVideo",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        640,
        640,
        81,
        1
      ]
    },
    {
      "id": 90,
      "type": "VAELoader",
      "pos": [
        60,
        190
      ],
      "size": [
        344.731689453125,
        59.98149108886719
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 0,
          "links": [
            176,
            185
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.45",
        "models": [
          {
            "name": "wan_2.1_vae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "wan_2.1_vae.safetensors"
      ]
    },
    {
      "id": 104,
      "type": "ModelSamplingSD3",
      "pos": [
        740,
        -230
      ],
      "size": [
        210,
        60
      ],
      "flags": {},
      "order": 24,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 190
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            195
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingSD3",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        5.000000000000001
      ]
    },
    {
      "id": 103,
      "type": "ModelSamplingSD3",
      "pos": [
        740,
        -100
      ],
      "size": [
        210,
        58
      ],
      "flags": {
        "collapsed": false
      },
      "order": 25,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 189
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            192
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "ModelSamplingSD3",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        5.000000000000001
      ]
    },
    {
      "id": 89,
      "type": "CLIPTextEncode",
      "pos": [
        440,
        290
      ],
      "size": [
        510,
        130
      ],
      "flags": {},
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 178
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            184
          ]
        }
      ],
      "title": "CLIP Text Encode (Negative Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 85,
      "type": "KSamplerAdvanced",
      "pos": [
        1000,
        250
      ],
      "size": [
        304.748046875,
        498.6905822753906
      ],
      "flags": {},
      "order": 29,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 192
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 168
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 169
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 170
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            175
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSamplerAdvanced",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "disable",
        0,
        "fixed",
        4,
        1,
        "euler",
        "simple",
        2,
        4,
        "disable"
      ]
    },
    {
      "id": 87,
      "type": "VAEDecode",
      "pos": [
        1320,
        -240
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 31,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 175
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 176
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            182
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": []
    },
    {
      "id": 94,
      "type": "CreateVideo",
      "pos": [
        1560,
        -270
      ],
      "size": [
        270,
        78
      ],
      "flags": {},
      "order": 33,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 182
        },
        {
          "name": "audio",
          "shape": 7,
          "type": "AUDIO",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "VIDEO",
          "type": "VIDEO",
          "links": [
            197
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CreateVideo",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        16
      ]
    },
    {
      "id": 62,
      "type": "LoadImage",
      "pos": [
        80,
        1740
      ],
      "size": [
        315,
        314
      ],
      "flags": {},
      "order": 5,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            133
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "slot_index": 1,
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "input-18.jpg",
        "image"
      ]
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1260,
        1110
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 30,
      "mode": 4,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 124
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 76
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            198
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": []
    },
    {
      "id": 109,
      "type": "CreateVideo",
      "pos": [
        1490,
        1110
      ],
      "size": [
        270,
        78
      ],
      "flags": {},
      "order": 32,
      "mode": 4,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 198
        },
        {
          "name": "audio",
          "shape": 7,
          "type": "AUDIO",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "VIDEO",
          "type": "VIDEO",
          "links": [
            199
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CreateVideo",
        "cnr_id": "comfy-core",
        "ver": "0.3.49"
      },
      "widgets_values": [
        16
      ]
    },
    {
      "id": 61,
      "type": "SaveVideo",
      "pos": [
        1260,
        1240
      ],
      "size": [
        710,
        808
      ],
      "flags": {},
      "order": 34,
      "mode": 4,
      "inputs": [
        {
          "name": "video",
          "type": "VIDEO",
          "link": 199
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveVideo",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "video/ComfyUI",
        "auto",
        "auto"
      ]
    },
    {
      "id": 106,
      "type": "MarkdownNote",
      "pos": [
        -350,
        1010
      ],
      "size": [
        370,
        110
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "1. Box-select then use Ctrl + B to enable\n2. If you don't want to run both groups simultaneously, don't forget to use **Ctrl + B** to disable the **fp8_scaled + 4steps LoRA** group after enabling the **fp8_scaled** group, or try the [partial - execution](https://docs.comfy.org/interface/features/partial-execution) feature."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 67,
      "type": "Note",
      "pos": [
        510,
        820
      ],
      "size": [
        390,
        88
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Video Size",
      "properties": {},
      "widgets_values": [
        "By default, we set the video to a smaller size for users with low VRAM. If you have enough VRAM, you can change the size"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 84,
      "type": "CLIPLoader",
      "pos": [
        60,
        30
      ],
      "size": [
        346.391845703125,
        106
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 0,
          "links": [
            178,
            181
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPLoader",
        "cnr_id": "comfy-core",
        "ver": "0.3.45",
        "models": [
          {
            "name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
        "wan",
        "default"
      ]
    },
    {
      "id": 93,
      "type": "CLIPTextEncode",
      "pos": [
        440,
        90
      ],
      "size": [
        510,
        160
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 181
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            183
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "Node name for S&R": "CLIPTextEncode",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "a cute anime girl picking up an assault rifle and moving quickly"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 97,
      "type": "LoadImage",
      "pos": [
        70,
        400
      ],
      "size": [
        315,
        314.0001220703125
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            186
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "slot_index": 1,
          "links": null
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "fennec360.png",
        "image"
      ]
    },
    {
      "id": 110,
      "type": "UnetLoaderGGUF",
      "pos": [
        105.25906372070312,
        -579.1570434570312
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            200
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UnetLoaderGGUF"
      },
      "widgets_values": [
        "wan2.2_i2v_high_noise_14B_Q4_K_S.gguf"
      ]
    },
    {
      "id": 111,
      "type": "UnetLoaderGGUF",
      "pos": [
        104.71427917480469,
        -454.8096618652344
      ],
      "size": [
        270,
        58
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            201
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "UnetLoaderGGUF"
      },
      "widgets_values": [
        "wan2.2_i2v_low_noise_14B_Q4_K_S.gguf"
      ]
    },
    {
      "id": 101,
      "type": "LoraLoaderModelOnly",
      "pos": [
        450,
        -230
      ],
      "size": [
        280,
        82
      ],
      "flags": {},
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 200
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            190
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly",
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "models": [
          {
            "name": "wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
            "directory": "loras"
          }
        ]
      },
      "widgets_values": [
        "wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors",
        1.0000000000000002
      ]
    },
    {
      "id": 102,
      "type": "LoraLoaderModelOnly",
      "pos": [
        450,
        -100
      ],
      "size": [
        280,
        82
      ],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 201
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            189
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "LoraLoaderModelOnly",
        "cnr_id": "comfy-core",
        "ver": "0.3.49",
        "models": [
          {
            "name": "wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors",
            "directory": "loras"
          }
        ]
      },
      "widgets_values": [
        "wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors",
        1.0000000000000002
      ]
    },
    {
      "id": 86,
      "type": "KSamplerAdvanced",
      "pos": [
        990,
        -250
      ],
      "size": [
        304.748046875,
        334
      ],
      "flags": {},
      "order": 27,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 195
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 172
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 173
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 174
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            170
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "KSamplerAdvanced",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        "enable",
        961207772327702,
        "randomize",
        4,
        1,
        "euler",
        "simple",
        0,
        2,
        "enable"
      ]
    },
    {
      "id": 112,
      "type": "MarkdownNote",
      "pos": [
        -490.0405578613281,
        321.6968688964844
      ],
      "size": [
        480,
        180
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Inference Time.  M3 Max 36GB.",
      "properties": {
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "## MacBook Pro. M3 Max. 36GB RAM. \n\n| Model            | Size |VRAM Usage | 1st Generation | 2nd Generation |\n|---------------------|-------|-----------|---------------|-----------------|\n| Q4                |240*240  | 22GB               | ≈  182s              | ≈ 149s                   |\n| Q4                |360*360  | 24GB               | ≈  457s              | ≈ 438s   85.14s/it80.3s/it \n| Q4                |480*480  |               | ≈                      | ≈                    |"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 108,
      "type": "SaveVideo",
      "pos": [
        1320,
        -140
      ],
      "size": [
        700,
        798
      ],
      "flags": {},
      "order": 35,
      "mode": 0,
      "inputs": [
        {
          "name": "video",
          "type": "VIDEO",
          "link": 197
        }
      ],
      "outputs": [],
      "properties": {
        "Node name for S&R": "SaveVideo",
        "cnr_id": "comfy-core",
        "ver": "0.3.49"
      },
      "widgets_values": [
        "video/ComfyUI",
        "auto",
        "auto"
      ]
    },
    {
      "id": 98,
      "type": "WanImageToVideo",
      "pos": [
        501.6954040527344,
        519.891357421875
      ],
      "size": [
        342.5999755859375,
        210
      ],
      "flags": {},
      "order": 23,
      "mode": 0,
      "inputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 183
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 184
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 185
        },
        {
          "name": "clip_vision_output",
          "shape": 7,
          "type": "CLIP_VISION_OUTPUT",
          "link": null
        },
        {
          "name": "start_image",
          "shape": 7,
          "type": "IMAGE",
          "link": 186
        }
      ],
      "outputs": [
        {
          "name": "positive",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            168,
            172
          ]
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "slot_index": 1,
          "links": [
            169,
            173
          ]
        },
        {
          "name": "latent",
          "type": "LATENT",
          "slot_index": 2,
          "links": [
            174
          ]
        }
      ],
      "properties": {
        "Node name for S&R": "WanImageToVideo",
        "cnr_id": "comfy-core",
        "ver": "0.3.45"
      },
      "widgets_values": [
        368,
        240,
        81,
        1
      ]
    },
    {
      "id": 66,
      "type": "MarkdownNote",
      "pos": [
        -470,
        -320
      ],
      "size": [
        480,
        530
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model Links",
      "properties": {},
      "widgets_values": [
        "[Tutorial](https://www.youtube.com/@tech-practice9805)\n\n**Diffusion Model**\n- [Q4_K_S high noise 14B](https://huggingface.co/bullerwins/Wan2.2-I2V-A14B-GGUF/resolve/main/wan2.2_i2v_high_noise_14B_Q4_K_S.gguf)\n- [Q4_K_S_low noise 14B](https://huggingface.co/bullerwins/Wan2.2-I2V-A14B-GGUF/resolve/main/wan2.2_i2v_low_noise_14B_Q4_K_S.gguf)\n- [wan2.2_i2v_high_noise_14B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_high_noise_14B_fp16.safetensors)\n- [wan2.2_i2v_low_noise_14B_fp16.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/diffusion_models/wan2.2_i2v_low_noise_14B_fp16.safetensors)\n\n**LoRA**\n- [wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors)\n- [wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/loras/wan2.2_i2v_lightx2v_4steps_lora_v1_high_noise.safetensors)\n\n**VAE**\n- [wan_2.1_vae.safetensors](https://huggingface.co/Comfy-Org/Wan_2.2_ComfyUI_Repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors)\n\n**Text Encoder**   \n- [umt5_xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors)\n\n\nFile save location\n\n```\nComfyUI/\n├───📂 models/\n│   ├───📂 diffusion_models/\n│   │   ├─── wan2.2_i2v_low_noise_14B_fp16.safetensors\n│   │   └─── wan2.2_i2v_high_noise_14B_fp16.safetensors\n│   ├───📂 loras/\n│   │   ├─── wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors\n│   │   └─── wan2.2_i2v_lightx2v_4steps_lora_v1_low_noise.safetensors\n│   ├───📂 text_encoders/\n│   │   └─── umt5_xxl_fp8_e4m3fn_scaled.safetensors \n│   └───📂 vae/\n│       └── wan_2.1_vae.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    }
  ],
  "links": [
    [
      74,
      38,
      0,
      6,
      0,
      "CLIP"
    ],
    [
      75,
      38,
      0,
      7,
      0,
      "CLIP"
    ],
    [
      76,
      39,
      0,
      8,
      1,
      "VAE"
    ],
    [
      110,
      37,
      0,
      54,
      0,
      "MODEL"
    ],
    [
      112,
      56,
      0,
      55,
      0,
      "MODEL"
    ],
    [
      113,
      57,
      0,
      58,
      3,
      "LATENT"
    ],
    [
      124,
      58,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      133,
      62,
      0,
      63,
      4,
      "IMAGE"
    ],
    [
      134,
      6,
      0,
      63,
      0,
      "CONDITIONING"
    ],
    [
      135,
      7,
      0,
      63,
      1,
      "CONDITIONING"
    ],
    [
      136,
      63,
      0,
      57,
      1,
      "CONDITIONING"
    ],
    [
      137,
      63,
      1,
      57,
      2,
      "CONDITIONING"
    ],
    [
      138,
      63,
      0,
      58,
      1,
      "CONDITIONING"
    ],
    [
      139,
      63,
      1,
      58,
      2,
      "CONDITIONING"
    ],
    [
      140,
      63,
      2,
      57,
      3,
      "LATENT"
    ],
    [
      141,
      39,
      0,
      63,
      2,
      "VAE"
    ],
    [
      147,
      54,
      0,
      57,
      0,
      "MODEL"
    ],
    [
      148,
      55,
      0,
      58,
      0,
      "MODEL"
    ],
    [
      168,
      98,
      0,
      85,
      1,
      "CONDITIONING"
    ],
    [
      169,
      98,
      1,
      85,
      2,
      "CONDITIONING"
    ],
    [
      170,
      86,
      0,
      85,
      3,
      "LATENT"
    ],
    [
      172,
      98,
      0,
      86,
      1,
      "CONDITIONING"
    ],
    [
      173,
      98,
      1,
      86,
      2,
      "CONDITIONING"
    ],
    [
      174,
      98,
      2,
      86,
      3,
      "LATENT"
    ],
    [
      175,
      85,
      0,
      87,
      0,
      "LATENT"
    ],
    [
      176,
      90,
      0,
      87,
      1,
      "VAE"
    ],
    [
      178,
      84,
      0,
      89,
      0,
      "CLIP"
    ],
    [
      181,
      84,
      0,
      93,
      0,
      "CLIP"
    ],
    [
      182,
      87,
      0,
      94,
      0,
      "IMAGE"
    ],
    [
      183,
      93,
      0,
      98,
      0,
      "CONDITIONING"
    ],
    [
      184,
      89,
      0,
      98,
      1,
      "CONDITIONING"
    ],
    [
      185,
      90,
      0,
      98,
      2,
      "VAE"
    ],
    [
      186,
      97,
      0,
      98,
      4,
      "IMAGE"
    ],
    [
      189,
      102,
      0,
      103,
      0,
      "MODEL"
    ],
    [
      190,
      101,
      0,
      104,
      0,
      "MODEL"
    ],
    [
      192,
      103,
      0,
      85,
      0,
      "MODEL"
    ],
    [
      195,
      104,
      0,
      86,
      0,
      "MODEL"
    ],
    [
      197,
      94,
      0,
      108,
      0,
      "VIDEO"
    ],
    [
      198,
      8,
      0,
      109,
      0,
      "IMAGE"
    ],
    [
      199,
      109,
      0,
      61,
      0,
      "VIDEO"
    ],
    [
      200,
      110,
      0,
      101,
      0,
      "MODEL"
    ],
    [
      201,
      111,
      0,
      102,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 10,
      "title": "fp8_scaled",
      "bounding": [
        40,
        980,
        1950,
        1123.5999755859375
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 1,
      "title": "Step1 - Load models",
      "bounding": [
        50,
        1020,
        371.0310363769531,
        571.3974609375
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2 - Upload start_image",
      "bounding": [
        50,
        1620,
        370,
        470
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step4 -  Prompt",
      "bounding": [
        440,
        1310,
        445.27801513671875,
        464.2060852050781
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Step3 - Video size & length",
      "bounding": [
        440,
        1790,
        440,
        300
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 15,
      "title": "fp8_scaled +  4steps LoRA",
      "bounding": [
        30,
        -350,
        2030,
        1120
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 11,
      "title": "Step1 - Load models",
      "bounding": [
        40,
        -310,
        371.0310363769531,
        571.3974609375
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 12,
      "title": "Step2 - Upload start_image",
      "bounding": [
        40,
        280,
        370,
        470
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 13,
      "title": "Step4 -  Prompt",
      "bounding": [
        430,
        20,
        530,
        420
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 14,
      "title": "Step3 - Video size & length",
      "bounding": [
        430,
        460,
        530,
        290
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 16,
      "title": "Lightx2v 4steps LoRA",
      "bounding": [
        430,
        -310,
        530,
        310
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 1.3513057093104042,
      "offset": [
        543.520169952519,
        470.3957373763923
      ]
    },
    "frontendVersion": "1.24.4",
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}